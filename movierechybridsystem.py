# -*- coding: utf-8 -*-
"""MovieRecHybridSystem.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iJrzGgdKE__akKbApm_rD8N8RzO46av9
"""

!pip install pandas numpy scikit-surprise

# Step 1: Import Libraries
import pandas as pd
import numpy as np
from sklearn.decomposition import TruncatedSVD
from sklearn.metrics.pairwise import cosine_similarity
from surprise import SVD, Dataset, Reader
from surprise.model_selection import train_test_split
from scipy.sparse import csr_matrix
import kagglehub

# Download latest version
path = kagglehub.dataset_download("grouplens/movielens-20m-dataset")
print("Path to dataset files:", path)
# Step 2: Load the dataset
dataset_path = "/root/.cache/kagglehub/datasets/grouplens/movielens-20m-dataset/versions/1"
ratings_path = f"{dataset_path}/rating.csv"

# Load the ratings dataset
ratings = pd.read_csv(ratings_path)

# Display the first few rows
print("Ratings Dataset:")
print(ratings.head())

# Step 3: Preprocess the dataset
ratings = ratings[['userId', 'movieId', 'rating']]

# Filter for active users and popular movies
print("Filtering data...")
user_counts = ratings['userId'].value_counts()
movie_counts = ratings['movieId'].value_counts()

active_users = user_counts[user_counts > 200].index  # Users with > 200 ratings
popular_movies = movie_counts[movie_counts > 500].index  # Movies with > 500 ratings

ratings_filtered = ratings[
    (ratings['userId'].isin(active_users)) & (ratings['movieId'].isin(popular_movies))
]
print(f"Filtered data: {ratings_filtered.shape[0]} ratings from {len(active_users)} users and {len(popular_movies)} movies.")

# Step 4: Create a sparse utility matrix
print("Creating sparse utility matrix...")
user_movie_matrix = ratings_filtered.pivot(index='userId', columns='movieId', values='rating').fillna(0)
sparse_utility_matrix = csr_matrix(user_movie_matrix.values)

# Step 5: Perform SVD for item similarity
print("Performing SVD...")
svd = TruncatedSVD(n_components=50, random_state=42)
latent_matrix = svd.fit_transform(sparse_utility_matrix)
item_matrix = svd.components_

# Compute item similarity using cosine similarity
item_similarity = cosine_similarity(item_matrix.T)
print("SVD and similarity computation completed.")

# Step 6: Collaborative Filtering with Surprise
print("Training Collaborative Filtering model...")
reader = Reader(rating_scale=(0.5, 5.0))
data = Dataset.load_from_df(ratings_filtered[['userId', 'movieId', 'rating']], reader)

# Split the dataset into training and testing sets
trainset, testset = train_test_split(data, test_size=0.2)

# Train an SVD model using Surprise
print("Training SVD model...")
cf_model = SVD(random_state=42)
cf_model.fit(trainset)
print("Collaborative Filtering model trained successfully.")

# Step 7: Hybrid Recommendation System


# Create a mapping of movieId to index for the item similarity matrix
movie_id_to_index = {movie_id: idx for idx, movie_id in enumerate(user_movie_matrix.columns)}

def hybrid_recommend(user_id, top_n=10):
    """Generate hybrid recommendations for a given user."""

    # Step 1: Get the user's rated movies and sort by rating
    user_rated_movies = user_movie_matrix.loc[user_id]
    top_rated_movies = user_rated_movies.sort_values(ascending=False).head(20)  # Top 20 rated by user

    # Step 2: Collaborative Filtering (CF) - predict ratings for all movies
    predictions = [
        (movie, cf_model.predict(user_id, movie).est) for movie in user_movie_matrix.columns
    ]
    predictions = sorted(predictions, key=lambda x: x[1], reverse=True)
    top_cf = predictions[:top_n]

    # Step 3: Item Similarity - consider only the top-rated movies
    rated_movie_ids = top_rated_movies.index  # Use only the top-rated movies
    similar_movies = {}

    for movie in rated_movie_ids:
        if movie in movie_id_to_index:
            movie_idx = movie_id_to_index[movie]
            similar = list(enumerate(item_similarity[movie_idx]))
            for sim_movie_idx, score in similar:
                sim_movie_id = user_movie_matrix.columns[sim_movie_idx]
                if sim_movie_id not in similar_movies:
                    similar_movies[sim_movie_id] = score
                else:
                    similar_movies[sim_movie_id] += score

    # Step 4: Calculate the hybrid score (CF + Item Similarity) and filter out negative scores
    hybrid_scores = {}
    for movie, score in top_cf:
        hybrid_scores[movie] = score + similar_movies.get(movie, 0)

    hybrid_recommendations = [
        (movie, score) for movie, score in hybrid_scores.items() if score > 0
    ]
    hybrid_recommendations = sorted(hybrid_recommendations, key=lambda x: x[1], reverse=True)

    return hybrid_recommendations[:top_n]


# Step 8: Test the Recommendation System
print("Generating recommendations...")
test_user_id = active_users[194]  # Use the given active user
recommended_movies = hybrid_recommend(test_user_id, top_n=10)

# Display recommendations
print(f"\nRecommendations for User {test_user_id}:")
for movie, score in recommended_movies:
    print(f"Movie ID: {movie}, Hybrid Score: {score:.2f}")

movies_path = f"{dataset_path}/movie.csv"
movies_df = pd.read_csv(movies_path)

# Merge the recommendations with movie titles
recommended_movies_with_titles = [
    (movie_id, score, movies_df[movies_df['movieId'] == movie_id]['title'].values[0])
    for movie_id, score in recommended_movies
]

print("\nRecommendations with Titles:")
for movie_id, score, title in recommended_movies_with_titles:
    print(f"Movie: {title}, Hybrid Score: {score:.2f}")

print("Recommendation process completed.")